{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import settings\n",
    "from simple_settings import settings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"Acquisition\": [\n",
    "        \"id\",\n",
    "        \"channel\",\n",
    "        \"seller\",\n",
    "        \"interest_rate\",\n",
    "        \"balance\",\n",
    "        \"loan_term\",\n",
    "        \"origination_date\",\n",
    "        \"first_payment_date\",\n",
    "        \"ltv\",\n",
    "        \"cltv\",\n",
    "        \"borrower_count\",\n",
    "        \"dti\",\n",
    "        \"borrower_credit_score\",\n",
    "        \"first_time_homebuyer\",\n",
    "        \"loan_purpose\",\n",
    "        \"property_type\",\n",
    "        \"unit_count\",\n",
    "        \"occupancy_status\",\n",
    "        \"property_state\",\n",
    "        \"zip\",\n",
    "        \"insurance_percentage\",\n",
    "        \"product_type\",\n",
    "        \"co_borrower_credit_score\",\n",
    "        \"mortgage_insurance_type\",\n",
    "        \"relocation_mortgage_indicator\"\n",
    "    ],\n",
    "    \"Performance\": [\n",
    "        \"id\",\n",
    "        \"reporting_period\",\n",
    "        \"servicer_name\",\n",
    "        \"interest_rate\",\n",
    "        \"balance\",\n",
    "        \"loan_age\",\n",
    "        \"months_to_maturity\",\n",
    "        \"adjusted_maturity\",\n",
    "        \"maturity_date\",\n",
    "        \"msa\",\n",
    "        \"delinquency_status\",\n",
    "        \"modification_flag\",\n",
    "        \"zero_balance_code\",\n",
    "        \"zero_balance_date\",\n",
    "        \"last_paid_installment_date\",\n",
    "        \"foreclosure_date\",\n",
    "        \"disposition_date\",\n",
    "        \"foreclosure_costs\",\n",
    "        \"property_repair_costs\",\n",
    "        \"recovery_costs\",\n",
    "        \"misc_costs\",\n",
    "        \"tax_costs\",\n",
    "        \"sale_proceeds\",\n",
    "        \"credit_enhancement_proceeds\",\n",
    "        \"repurchase_proceeds\",\n",
    "        \"other_foreclosure_proceeds\",\n",
    "        \"non_interest_bearing_balance\",\n",
    "        \"principal_forgiveness_balance\",\n",
    "        \"repurchase_make_whole_proceed_flag\",\n",
    "        \"forclosure_principal write-off amount\",\n",
    "        \"servicing_activity_indicator\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "SELECT = {\n",
    "    \"Acquisition\": HEADERS[\"Acquisition\"],\n",
    "    \"Performance\": [\n",
    "        'id','reporting_period','servicer_name','balance','loan_age','maturity_date','delinquency_status',\n",
    "                     'foreclosure_date','disposition_date'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\loan-prediction-masterssss\\data_year2014\\2014Q1\\Performance_2014Q1.txt\n",
      "9172863\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\2014Q2\\Performance_2014Q2.txt\n",
      "10188168\n",
      "19361031\n"
     ]
    }
   ],
   "source": [
    "#tested\n",
    "import os,glob,fileinput\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "def concatenate():\n",
    "    with open(\"Performance_output.txt\", \"w\") as a:\n",
    "\n",
    "        for path, subdirs, files in os.walk(r'D:\\loan-prediction-masterssss\\data_year2014'):\n",
    "            files = [ fi for fi in files if fi.startswith(\"Performance\") ]\n",
    "            for filename in files:\n",
    "                f = os.path.join(path, filename)\n",
    "                print(f)\n",
    "\n",
    "                with open(f) as fin:\n",
    "                    for line in fin:\n",
    "                        a.write(line)\n",
    "\n",
    "                total_line_count = sum(1 for line in open(f))\n",
    "                print(total_line_count)\n",
    "\n",
    "concatenate()\n",
    "\n",
    "copyfile(\"Performance_output.txt\", 'D:\\loan-prediction-masterssss\\data_year2014\\combined\\Performance_output.txt')\n",
    "\n",
    "total_line_count1 = sum(1 for line in open('Performance_output.txt'))\n",
    "print(total_line_count1)\n",
    "\n",
    "os.remove(\"Performance_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selecting the columns and saving the acquisition file\n",
    "data = pd.read_csv('D:\\loan-prediction-masterssss\\data_year2014\\combined\\Acquisition_output.txt', sep=\"|\", \n",
    "                   header=None,names=HEADERS['Acquisition'])\n",
    "data = data[SELECT['Acquisition']]\n",
    "\n",
    "data.to_csv('D:\\loan-prediction-masterssss\\data_year2014\\combined\\Acquisition_output_col.txt', sep='|',\n",
    "            header=SELECT['Acquisition'], index=False)\n",
    "\n",
    "#print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athiq.ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Selecting the columns and saving the performance file\n",
    "data = pd.read_csv(r'D:\\loan-prediction-masterssss\\data_year2014\\combined\\Performance_output.txt', sep=\"|\", \n",
    "                   header=None,names=HEADERS['Performance'])\n",
    "data = data[SELECT['Performance']]\n",
    "data.to_csv(r'D:\\loan-prediction-masterssss\\data_year2014\\combined\\Performance_output_col.txt', sep='|',\n",
    "            header=SELECT['Performance'], index=False)\n",
    "\n",
    "#print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athiq.ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#dont run this program, this will hang your sytem, since the file size is large\n",
    "\n",
    "#Get the latest record per loan id based on the foreclosure date\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r'D:\\loan-prediction-masterssss\\data_year2014\\2014Q1\\Performance_2014Q1.txt', sep=\"|\", \n",
    "                   header=None,names=HEADERS['Performance'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#problem : This is appending the data again and again\n",
    "#This code will merge the files available in the directory and save it as resultsthree.txt\n",
    "import os\n",
    "path = os.chdir('D:/loan-prediction-masterssss/data_year2014/test') # Provide the path here\n",
    "dirs = os.listdir(path)\n",
    "print (os.getcwd())\n",
    "print(dirs)\n",
    "\n",
    "#filenames = ['resultsone.txt', 'resultstwo.txt']\n",
    "with open('resultsthree.txt', 'w') as outfile:\n",
    "    for fname in dirs:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Acquisition_2014Q1 - Copy.txt\n",
      "Before Acquisition_2014Q1.txt\n",
      "Before pandas_simple.xlsx\n",
      "Before resultsthree.txt\n",
      "Before Performance.txt\n",
      "Before Performance_2014Q1_sample.csv\n",
      "Before Performance_2014Q1_sample.txt\n",
      "Before sample_Performance_2014Q1.txt\n"
     ]
    }
   ],
   "source": [
    "#It lists the files within the directory\n",
    "for path, subdirs, files in os.walk(r'D:\\loan-prediction-masterssss\\data_year2014\\test'):\n",
    "            for filename in files:\n",
    "                print(\"Before\",filename)\n",
    "                if filename.startswith('Acquistion_*'):\n",
    "                    print(\"After\",filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "full=[]\n",
    "# Open a file\n",
    "path = \"D:\\loan-prediction-masterssss\\data_test\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "#new_file=[]\n",
    "print(\"Main directory - \",path)\n",
    "# This would print all the files and directories\n",
    "for i in dirs:\n",
    "    print(\"Files in the main directory - \", i)\n",
    "    new_path = os.path.join(path, i)\n",
    "    new_dirs=os.listdir(new_path)\n",
    "    print(\"The new path is - \",new_path)\n",
    "    print(\"Files in the sub directory - \",new_dirs)\n",
    "    new_dirs_str = str(new_dirs).strip(\"[]''\")\n",
    "    new_path_str=str(new_path)\n",
    "    new_file = os.path.join(new_path_str,new_dirs_str)\n",
    "    data = pd.read_table(new_file, sep=\"|\", header=None)\n",
    "    print(data.head())\n",
    "    data1 = np.array(data)\n",
    "    full.append(data1)\n",
    "    #image_file = file.readline()\n",
    "    #new_file.append(data)\n",
    "    \n",
    "    print(full)\n",
    "\n",
    "    count=0\n",
    "    for line in new_file:\n",
    "    #       count+=1\n",
    "\n",
    "    #print (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "full=[]\n",
    "# Open a file\n",
    "path = \"D:\\loan-prediction-masterssss\\data_test\"\n",
    "dirs = os.listdir(path)\n",
    "#print(dirs)\n",
    "\n",
    "#new_file=[]\n",
    "print(\"Main directory - \",path)\n",
    "# This would print all the files and directories\n",
    "for i in dirs:\n",
    "    print(\"Files in the main directory - \", i)\n",
    "    new_path = os.path.join(path, i)\n",
    "    new_dirs=os.listdir(new_path)\n",
    "    print(\"The new path is - \",new_path)\n",
    "    print(\"Files in the sub directory - \",new_dirs)\n",
    "    path = os.chdir(new_path) # Provide the path here\n",
    "    dirs = os.listdir(path)\n",
    "    print ('New directory is now - ',os.getcwd())\n",
    "    print(dirs)\n",
    "\n",
    "    import fileinput\n",
    "    import glob\n",
    "\n",
    "    file_list = glob.glob(\"*.txt\")\n",
    "\n",
    "    with open('result.txt', 'w') as file:\n",
    "        input_lines = fileinput.input(file_list)\n",
    "        file.writelines(input_lines)\n",
    "        if len('result.txt')>0:\n",
    "            print(\"Result exported\")\n",
    "        full.append('result.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,glob,fileinput\n",
    "import pandas as pd\n",
    "\n",
    "full =[]\n",
    "def scanfolder():\n",
    "    os.chdir(\"D:\\loan-prediction-masterssss\\data_test\\combined\")\n",
    "    with open('result.txt','w') as file:\n",
    "        for path, dirs, files in os.walk('D:\\loan-prediction-masterssss\\data_test'):\n",
    "            for directory_name in dirs:\n",
    "                for file_name in glob.iglob(os.path.join(path, directory_name, '*.txt')):\n",
    "                    print (file_name)\n",
    "                    #with open('result.txt','w') as file:\n",
    "                    input_lines = fileinput.input(file_name)\n",
    "                    file.writelines(input_lines)\n",
    "\n",
    "                    total_line_count = sum(1 for line in open(file_name))\n",
    "                    print(total_line_count)\n",
    "\n",
    "                    #full.append(file_name)\n",
    "scanfolder()\n",
    "#data = pd.read_table('result.txt', sep=\"|\", header=None)\n",
    "\n",
    "#print(data.head())\n",
    "#https://automatetheboringstuff.com/chapter8/\n",
    "#https://stackoverflow.com/questions/12199120/python-list-all-the-file-names-in-a-directory-and-its-subdirectories-and-then-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path, subdirs, files in os.walk(r'D:\\loan-prediction-masterssss\\data_year2104'):\n",
    "    for filename in files:\n",
    "        f = os.path.join(path, filename)\n",
    "        print('f here ',f)\n",
    "        print(path)\n",
    "        print(subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012Q1\n",
      "2012Q2\n",
      "2012Q3\n",
      "2012Q4\n",
      "2013Q1\n",
      "2013Q2\n",
      "2013Q3\n",
      "2013Q4\n",
      "2014Q1\n",
      "2014Q2\n",
      "2014Q3\n",
      "2014Q4\n",
      "2015Q1\n",
      "Combined\n"
     ]
    }
   ],
   "source": [
    "#Tested\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# Open a file\n",
    "path = \"D:\\loan-prediction-masterssss\\data\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "# This would print all the files and directories\n",
    "for file in dirs:\n",
    "    print (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of lines to be read1\n",
      "100000506220|03/01/2014|OTHER|4.75||0|360|360|03/2044|31080|0|N|||||||||||||||||||N\n",
      "\n",
      "Total number of observations -  9172863\n"
     ]
    }
   ],
   "source": [
    "#Tested - Read the files with the number of lines specified by the user and also count the total number of records in the file\n",
    "nos = int(input('Enter the number of lines to be read'))\n",
    "file = open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1.txt\", \"r\")\n",
    "\n",
    "for i in range(nos):\n",
    "    image_file = file.readline()\n",
    "print(image_file)\n",
    "\n",
    "#Method - 1\n",
    "total_line_count = sum(1 for line in open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1.txt\"))\n",
    "print(\"Total number of observations - \",total_line_count)\n",
    "\n",
    "#Method - 2\n",
    "#count=0\n",
    "#with open (r\"D:/loan-prediction-masterssss/data/2012Q1/Acquisition_2012Q1.txt\",'rb') as f:\n",
    "#    for line in f:\n",
    "#        count+=1\n",
    "\n",
    "#print (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of lines to be read10\n",
      "Total number of observations -  9172863\n",
      "             id  foreclosure_date\n",
      "0  100000506220               NaN\n",
      "1  100000506220               NaN\n",
      "2  100000506220               NaN\n",
      "3  100000506220               NaN\n",
      "4  100000506220               NaN\n"
     ]
    }
   ],
   "source": [
    "#Tested\n",
    "nos = int(input('Enter the number of lines to be read - '))\n",
    "file = open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1.txt\", \"r\")\n",
    "with open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt\", \"w\") as outfile:\n",
    "    for i in range(nos):\n",
    "        image_file = file.readline()\n",
    "        outfile.write(image_file)\n",
    "    #print(image_file)\n",
    "\n",
    "#Total number of observations\n",
    "total_line_count = sum(1 for line in open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1.txt\"))\n",
    "print(\"Total number of observations - \",total_line_count)\n",
    "\n",
    "#Opened the saved file and print it\n",
    "file = open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt\", \"r\")\n",
    "#print (file.read())\n",
    "\n",
    "#Create the headers for the saved file\n",
    "import pandas as pd\n",
    "data = pd.read_table(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt', sep=\"|\", \n",
    "                   header=None,names=HEADERS['Performance'])\n",
    "data = data[SELECT['Performance']]\n",
    "print(data.head())\n",
    "#newdf = data[data.columns[14:16]]\n",
    "#print(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of lines to be read in the performance dataset - 90000\n",
      "train dataset -                  id reporting_period servicer_name    balance  loan_age  \\\n",
      "72279  107110636463       2015-04-01           NaN   64275.10        13   \n",
      "10363  100993153605       2017-06-01           NaN  207744.70        40   \n",
      "33219  103311706272       2014-10-01           NaN   99253.17         9   \n",
      "61748  106097819088       2017-06-01           NaN  242271.66        41   \n",
      "26545  102649378192       2017-06-01           NaN  144192.19        39   \n",
      "\n",
      "      maturity_date delinquency_status foreclosure_date  disposition_date  \n",
      "72279       03/2029                  X              NaT               NaN  \n",
      "10363       02/2034                  1              NaT               NaN  \n",
      "33219       01/2044                  X              NaT               NaN  \n",
      "61748       01/2034                  0              NaT               NaN  \n",
      "26545       03/2029                  0              NaT               NaN  \n",
      "test dataset -                  id reporting_period servicer_name    balance  loan_age  \\\n",
      "49008  104875161308       2017-06-01           NaN  208731.03        39   \n",
      "68464  106730849339       2017-06-01           NaN  124270.24        38   \n",
      "36670  103641207112       2017-06-01           NaN   60163.03        41   \n",
      "77513  107562930588       2017-06-01           NaN  101334.07        41   \n",
      "88078  108571100267       2015-02-01           NaN  362475.64        12   \n",
      "\n",
      "      maturity_date delinquency_status foreclosure_date  disposition_date  \n",
      "49008       03/2044                  0              NaT               NaN  \n",
      "68464       04/2044                  0              NaT               NaN  \n",
      "36670       01/2029                  0              NaT               NaN  \n",
      "77513       01/2044                  0              NaT               NaN  \n",
      "88078       02/2044                  X              NaT               NaN  \n",
      "The number of observations in the dataset are -  2690\n",
      "The number of variables in the dataset are -  9\n"
     ]
    }
   ],
   "source": [
    "#tested - performance dataset\n",
    "import numpy as np\n",
    "nos = int(input('Enter the number of lines to be read in the performance dataset - '))\n",
    "file = open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1.txt\", \"r\")\n",
    "with open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt\", \"w\") as outfile:\n",
    "    for i in range(nos):\n",
    "        input_file = file.readline()\n",
    "        outfile.write(input_file)\n",
    "    #print(image_file)\n",
    "\n",
    "#Opened the saved file and print it\n",
    "#file = open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt\", \"r\")\n",
    "#print (file.read())\n",
    "\n",
    "#Total number of observations\n",
    "#total_line_count = sum(1 for line in open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1.txt\"))\n",
    "#print(\"Total number of observations - \",total_line_count) - 9172863\n",
    "\n",
    "\n",
    "#Create the headers for the saved file\n",
    "import pandas as pd\n",
    "data = pd.read_table(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt', sep=\"|\", \n",
    "                   header=None,names=HEADERS['Performance'],low_memory=False)\n",
    "\n",
    "#To see the data type of a dataframe\n",
    "#dtypeCount =[data.iloc[:,i].apply(type).value_counts() for i in range(data.shape[1])]\n",
    "#print(dtypeCount)\n",
    "\n",
    "\n",
    "#Selecting the specific columns in the dataset\n",
    "data = data[['id','reporting_period','servicer_name','balance','loan_age','maturity_date','delinquency_status',\n",
    "               'foreclosure_date','disposition_date']]\n",
    "\n",
    "#Converting the reporting period to date field\n",
    "data['reporting_period'] = pd.to_datetime(data['reporting_period'])\n",
    "data['foreclosure_date'] = pd.to_datetime(data['foreclosure_date'])\n",
    "#print(data.head())\n",
    "\n",
    "#Filtering only to pull the foreclosed loan\n",
    "#data2 = data[data.id==105500404289]\n",
    "data3 = data.sort_values(by='reporting_period',ascending=False)\n",
    "data4 = data3.drop_duplicates('id')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data4, test_size=0.4)\n",
    "\n",
    "train.to_csv(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.csv',\n",
    "             header=True, index=False, sep='|', mode='w')\n",
    "\n",
    "#df1 = data4.iloc[:3, :]\n",
    "#df2 = data4.iloc[:2, :]\n",
    "\n",
    "#print('df1 dataset -', df1)\n",
    "#print('df2 dataset -', df2)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('train dataset -', train.head())\n",
    "print('test dataset -', test.head())\n",
    "\n",
    "#data4 = data3.id.unique()\n",
    "#data4 = np.unique(data3.id, axis = 0)\n",
    "#np.unique(a, return_inverse=True)\n",
    "#df = df.drop_duplicates('COL2')\n",
    "\n",
    "#print(data.delinquency_status.unique())\n",
    "#data3.head(1)\n",
    "#data2 = data[data.foreclosure_date.notnull()]\n",
    "#print(data2.head(5))\n",
    "#print(data2[data2.columns[1]])\n",
    "#print(data3.head(5).loc[:,['id','reporting_period','servicer_name','balance','loan_age','maturity_date','delinquency_status',\n",
    "#                  'foreclosure_date','disposition_date']])\n",
    "\n",
    "\n",
    "#print(data4.head(5))\n",
    "\n",
    "Count_Row=data4.shape[0] #gives number of row count\n",
    "Count_Col=data4.shape[1] #gives number of col count\n",
    "\n",
    "print('The number of observations in the dataset are - ',Count_Row)\n",
    "print('The number of variables in the dataset are - ',Count_Col)\n",
    "#print(data4[data4.foreclosure_date.notnull()])\n",
    "#print(data4[data4.id==105500404289])\n",
    "#print(data.delinquency_status.unique())\n",
    "#newdf = data[data.columns[14:16]]\n",
    "#print(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate(prefix=\"Acquisition\"):\n",
    "    files = os.listdir(settings.DATA_DIR)\n",
    "    full = []\n",
    "    for f in files:\n",
    "        if not f.startswith(prefix):\n",
    "            continue\n",
    "\n",
    "        data = pd.read_csv(os.path.join(settings.DATA_DIR, f), sep=\"|\", header=None, names=HEADERS[prefix], index_col=False)\n",
    "        data = data[SELECT[prefix]]\n",
    "        full.append(data)\n",
    "\n",
    "    full = pd.concat(full, axis=0)\n",
    "\n",
    "    full.to_csv(os.path.join(settings.PROCESSED_DIR, \"{}.txt\".format(prefix)), sep=\"|\", header=SELECT[prefix], index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    concatenate(\"Acquisition\")\n",
    "    concatenate(\"Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir('D:/loan-prediction-masterssss/data_year2014/2014Q1')\n",
    "print(files)\n",
    "\n",
    "#os.walk(r'D:\\loan-prediction-masterssss\\data_year2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the dataset are -  274821\n",
      "The number of variables in the dataset are -  9\n"
     ]
    }
   ],
   "source": [
    "#Tested - performance dataset\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#def ProcessLargeTextFile():\n",
    "#    with open(\"filepath\", \"r\") as r, open(\"outfilepath\", \"w\") as w:\n",
    "#        for line in r:\n",
    "\n",
    "filename = 'Performance_2014Q1.txt'\n",
    "filepath = 'D:/loan-prediction-masterssss/data_year2014/2014Q1'\n",
    "\n",
    "#with open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt\", \"r\") as infile:\n",
    "for i in range(1):\n",
    "    data = pd.read_csv(os.path.join(filepath,filename), sep=\"|\",header=None,names=HEADERS['Performance'],low_memory=False)\n",
    "    data = data[['id','reporting_period','servicer_name','balance','loan_age','maturity_date','delinquency_status',\n",
    "                 'foreclosure_date','disposition_date']]\n",
    "    data['reporting_period'] = pd.to_datetime(data['reporting_period'])\n",
    "    data['foreclosure_date'] = pd.to_datetime(data['foreclosure_date'])\n",
    "    data3 = data.sort_values(by='reporting_period',ascending=False)\n",
    "    data4 = data3.drop_duplicates('id')\n",
    "    data4.to_csv(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.csv',\n",
    "                 header=True, index=False, sep='|', mode='w')\n",
    "\n",
    "\n",
    "Count_Row=data4.shape[0] #gives number of row count\n",
    "Count_Col=data4.shape[1] #gives number of col count\n",
    "\n",
    "print('The number of observations in the dataset are - ',Count_Row)\n",
    "print('The number of variables in the dataset are - ',Count_Col)\n",
    "#Total number of observations -  9,172,863\n",
    "#The number of observations in the dataset are -  274,821\n",
    "                       \n",
    "#data.iloc[:,1:7] = data.iloc[:,7:12].apply(pd.to_datetime, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_Performance_2014Q1.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filepath = 'D:/loan-prediction-masterssss/data_year2014/2014Q1'\n",
    "files = os.listdir(filepath)\n",
    "for i in files:\n",
    "    if i.startswith( 'sample' ):\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\loan-prediction-masterssss\\data_year2014\\2014Q1\\Acquisition_2014Q1.txt\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\2014Q1\\Performance_2014Q1.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for path, dirs, files in os.walk(r'D:\\loan-prediction-masterssss\\data_year2014\\2014Q1'):\n",
    "    for directory_name in dirs:\n",
    "        #for file_name in glob.iglob(os.path.join(path, directory_name, '*.txt')):\n",
    "        for file_name in glob.iglob(os.path.join(path, '*.txt')):\n",
    "            print (file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename is - ['Performance_2014Q1.txt']\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\2014Q1\\Performance_2014Q1.txt\n",
      "filename is - ['Performance_2014Q2.txt']\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\2014Q2\\Performance_2014Q2.txt\n",
      "filename is - ['Performance_output.txt', 'Performance_output_col.txt']\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\combined\\Performance_output.txt\n",
      "filename is - ['Performance_output.txt', 'Performance_output_col.txt']\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\combined\\Performance_output_col.txt\n",
      "filename is - ['Performance.txt', 'Performance_2014Q1_sample.csv', 'Performance_2014Q1_sample.txt']\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\test\\New folder\\Performance.txt\n",
      "filename is - ['Performance.txt', 'Performance_2014Q1_sample.csv', 'Performance_2014Q1_sample.txt']\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\test\\New folder\\Performance_2014Q1_sample.csv\n",
      "filename is - ['Performance.txt', 'Performance_2014Q1_sample.csv', 'Performance_2014Q1_sample.txt']\n",
      "D:\\loan-prediction-masterssss\\data_year2014\\test\\New folder\\Performance_2014Q1_sample.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for path, subdirs, files in os.walk(r'D:\\loan-prediction-masterssss\\data_year2014'):\n",
    "            files = [ fi for fi in files if fi.startswith(\"Performance\") ]\n",
    "            for filename in files:\n",
    "                path_files = os.path.join(path, filename)\n",
    "                #print(path)\n",
    "                print('filename is -',files)\n",
    "                print(path_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of files -  ['Acquisition_2014Q1.txt', 'Performance_2014Q1.txt']\n",
      "The value of i -  Acquisition_2014Q1.txt\n",
      "The number of observations in the dataset are -  274821\n",
      "The number of variables in the dataset are -  25\n",
      "The value of i -  Performance_2014Q1.txt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'reporting_period'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2521\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2523\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reporting_period'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-df8c1736fe0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mlarge_files_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acquisition\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mlarge_files_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Performance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-df8c1736fe0b>\u001b[0m in \u001b[0;36mlarge_files_process\u001b[1;34m(prefix)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHEADERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSELECT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reporting_period'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reporting_period'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'foreclosure_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'foreclosure_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reporting_period'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3837\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3838\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3839\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3840\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2522\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2523\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2524\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reporting_period'"
     ]
    }
   ],
   "source": [
    "#wip - trying to do in a loop format\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "filepath = 'D:/loan-prediction-masterssss/data_year2014/2014Q1'\n",
    "\n",
    "def large_files_process(prefix):\n",
    "    files = os.listdir(filepath)\n",
    "    print('list of files - ' ,files)\n",
    "    for i in files:\n",
    "        if i.startswith( 'Performance' ):\n",
    "            print('The value of i - ', i)\n",
    "            data = pd.read_csv(os.path.join(filepath,i), sep=\"|\",header=None,names=HEADERS[prefix],low_memory=False)\n",
    "            data = data[SELECT[prefix]]\n",
    "            data['reporting_period'] = pd.to_datetime(data['reporting_period'])\n",
    "            data['foreclosure_date'] = pd.to_datetime(data['foreclosure_date'])\n",
    "            data1 = data.sort_values(by='reporting_period',ascending=False)\n",
    "            data2 = data1.drop_duplicates('id')\n",
    "            data2.to_csv(os.path.join(filepath, \"{}_recent_col.txt\".format(prefix)),header=True, index=False, sep='|', mode='w')\n",
    "\n",
    "\n",
    "            Count_Row=data2.shape[0] #gives number of row count\n",
    "            Count_Col=data2.shape[1] #gives number of col count\n",
    "\n",
    "            print('The number of observations in the dataset are - ',Count_Row)\n",
    "            print('The number of variables in the dataset are - ',Count_Col)\n",
    "            \n",
    "        elif i.startswith('Acquisition'):\n",
    "            print('The value of i - ', i)\n",
    "            data = pd.read_csv(os.path.join(filepath,i), sep=\"|\",header=None,names=HEADERS[prefix],low_memory=False)\n",
    "            data.to_csv(os.path.join(filepath, \"{}_col.txt\".format(prefix)),header=True, index=False, sep='|', mode='w')\n",
    "\n",
    "            Count_Row=data.shape[0] #gives number of row count\n",
    "            Count_Col=data.shape[1] #gives number of col count\n",
    "\n",
    "            print('The number of observations in the dataset are - ',Count_Row)\n",
    "            print('The number of variables in the dataset are - ',Count_Col)\n",
    "        \n",
    "        else:\n",
    "            break\n",
    "\n",
    "large_files_process(\"Acquisition\")\n",
    "large_files_process(\"Performance\")\n",
    "\n",
    "print(\"I am done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of files -  ['Acquisition_2014Q1.txt', 'Acquisition_col.txt', 'Performance_2014Q1.txt']\n",
      "The value of i -  Acquisition_2014Q1.txt\n",
      "The number of observations in the dataset are -  274821\n",
      "The number of variables in the dataset are -  25\n",
      "The value of i -  Acquisition_col.txt\n",
      "The number of observations in the dataset are -  274822\n",
      "The number of variables in the dataset are -  25\n"
     ]
    }
   ],
   "source": [
    "#wip - trying to do in a loop format\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "filepath = 'D:/loan-prediction-masterssss/data_year2014/2014Q1'\n",
    "\n",
    "def large_files_process(prefix):\n",
    "    files = os.listdir(filepath)\n",
    "    print('list of files - ' ,files)\n",
    "    \n",
    "    for i in files:\n",
    "        data = pd.read_csv(os.path.join(filepath,i), sep=\"|\",header=None,names=HEADERS[prefix],low_memory=False)\n",
    "        data = data[SELECT[prefix]]\n",
    "        \n",
    "        if i.startswith( 'Performance' ):\n",
    "            print('The value of i - ', i)\n",
    "            data['reporting_period'] = pd.to_datetime(data['reporting_period'])\n",
    "            data['foreclosure_date'] = pd.to_datetime(data['foreclosure_date'])\n",
    "            data = data.sort_values(by='reporting_period',ascending=False)\n",
    "            data = data.drop_duplicates('id')\n",
    "            data.to_csv(os.path.join(filepath, \"{}_recent_col.txt\".format(prefix)),header=True, index=False, sep='|', mode='w')\n",
    "\n",
    "        elif i.startswith('Acquisition'):\n",
    "            print('The value of i - ', i)\n",
    "            data = pd.read_csv(os.path.join(filepath,i), sep=\"|\",header=None,names=HEADERS[prefix],low_memory=False)\n",
    "            data.to_csv(os.path.join(filepath, \"{}_col.txt\".format(prefix)),header=True, index=False, sep='|', mode='w')\n",
    "           \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        Count_Row=data.shape[0] #gives number of row count\n",
    "        Count_Col=data.shape[1] #gives number of col count\n",
    "\n",
    "        print('The number of observations in the dataset are - ',Count_Row)\n",
    "        print('The number of variables in the dataset are - ',Count_Col)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "large_files_process(\"Acquisition\")\n",
    "print(\"I am done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copied again\n",
    "import os,glob,fileinput\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "def concatenate():\n",
    "    with open(\"Performance_output.txt\", \"w\") as a:\n",
    "\n",
    "        for path, subdirs, files in os.walk(r'D:\\loan-prediction-masterssss\\data_year2014'):\n",
    "            files = [ fi for fi in files if fi.startswith(\"Performance\") ]\n",
    "            for filename in files:\n",
    "                f = os.path.join(path, filename)\n",
    "                print(f)\n",
    "\n",
    "                with open(f) as fin:\n",
    "                    for line in fin:\n",
    "                        a.write(line)\n",
    "\n",
    "                total_line_count = sum(1 for line in open(f))\n",
    "                print(total_line_count)\n",
    "\n",
    "concatenate()\n",
    "\n",
    "copyfile(\"Performance_output.txt\", 'D:\\loan-prediction-masterssss\\data_year2014\\combined\\Performance_output.txt')\n",
    "\n",
    "total_line_count1 = sum(1 for line in open('Performance_output.txt'))\n",
    "print(total_line_count1)\n",
    "\n",
    "os.remove(\"Performance_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(data[data.foreclosure_date.notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id reporting_period servicer_name  balance  loan_age  \\\n",
      "56059  105500404289       2014-01-01         OTHER      NaN        -1   \n",
      "\n",
      "      maturity_date delinquency_status foreclosure_date  disposition_date  \n",
      "56059       02/2044                  0              NaT               NaN  \n"
     ]
    }
   ],
   "source": [
    "print(data4[data4.id==105500404289])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outputing the recent records of the performance dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(os.path.join(r'D:/loan-predicction-masterssss/data_year2014/2014Q1','Performance_2014Q1_sample.txt'),\n",
    "                   sep=\"|\", header=None,names=HEADERS['Performance'], index_col=False,low_memory=False,chunksize=4)\n",
    "\n",
    "data['reporting_period'] = pd.to_datetime(data['reporting_period'])\n",
    "#data['foreclosure_date'] = pd.to_datetime(data['foreclosure_date'])\n",
    "\n",
    "#data = data.loc[:,['id','reporting_period','servicer_name','balance','loan_age','maturity_date','delinquency_status',\n",
    "#                   'foreclosure_date']].sort_values(by='reporting_period',ascending=0)\n",
    "\n",
    "#data.head(1).to_csv(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_recent.csv',\n",
    "#            index=False,sep='|', mode='w')\n",
    "\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "LARGE_FILE = \"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt\"\n",
    "CHUNKSIZE = 100000 # processing 100,000 rows at a time\n",
    "\n",
    "def process_frame(df):\n",
    "        # process data frame\n",
    "        return len(df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        reader = pd.read_table(LARGE_FILE, chunksize=CHUNKSIZE)\n",
    "\n",
    "        result = 0\n",
    "        for df in reader:\n",
    "                # process each data frame\n",
    "                #result += process_frame(df)\n",
    "                import pandas as pd\n",
    "                data = pd.read_table(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1.txt', sep=\"|\", \n",
    "                header=None,names=HEADERS['Performance'],low_memory=False)\n",
    "                \n",
    "                data['reporting_period'] = pd.to_datetime(data['reporting_period'])\n",
    "                data['foreclosure_date'] = pd.to_datetime(data['foreclosure_date'])\n",
    "                \n",
    "                data = data.loc[:,['id','reporting_period','servicer_name','balance','loan_age','maturity_date',\n",
    "                                   'delinquency_status','foreclosure_date']].sort_values(by='reporting_period',ascending=0)\n",
    "                \n",
    "                data.head(5).to_csv(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_recent.csv',\n",
    "                                    index=False,sep='|', mode='w')\n",
    "\n",
    "        print (\"There are %d rows of data\"%(result))\n",
    "        print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of lines to be read90000\n",
      "Total number of observations -  274821\n",
      "                id channel seller  interest_rate  balance  loan_term  \\\n",
      "1681  105500404289       R  OTHER          5.125   111000        360   \n",
      "\n",
      "     origination_date first_payment_date  ltv  cltv  \\\n",
      "1681          01/2014            03/2014   70    70   \n",
      "\n",
      "                  ...                property_type  unit_count  \\\n",
      "1681              ...                           SF           1   \n",
      "\n",
      "      occupancy_status property_state  zip insurance_percentage  product_type  \\\n",
      "1681                 P             IL  614                  NaN           FRM   \n",
      "\n",
      "     co_borrower_credit_score mortgage_insurance_type  \\\n",
      "1681                    634.0                     NaN   \n",
      "\n",
      "      relocation_mortgage_indicator  \n",
      "1681                              N  \n",
      "\n",
      "[1 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#tested - Acquisition dataset\n",
    "nos = int(input('Enter the number of lines to be read in the Acquisition dataset - '))\n",
    "file = open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Acquisition_2014Q1.txt\", \"r\")\n",
    "with open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Acquisition_2014Q1_sample.txt\", \"w\") as outfile:\n",
    "    for i in range(nos):\n",
    "        input_file = file.readline()\n",
    "        outfile.write(input_file)\n",
    "    #print(image_file)\n",
    "\n",
    "#Opened the saved file and print it\n",
    "#file = open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Performance_2014Q1_sample.txt\", \"r\")\n",
    "#print (file.read())\n",
    "\n",
    "#Total number of observations\n",
    "total_line_count = sum(1 for line in open(r\"D:/loan-prediction-masterssss/data_year2014/2014Q1/Acquisition_2014Q1.txt\"))\n",
    "print(\"Total number of observations - \",total_line_count) \n",
    "#274821\n",
    "\n",
    "#Create the headers for the saved file\n",
    "import pandas as pd\n",
    "data = pd.read_table(r'D:/loan-prediction-masterssss/data_year2014/2014Q1/Acquisition_2014Q1_sample.txt', sep=\"|\", \n",
    "                   header=None,names=HEADERS['Acquisition'],low_memory=False)\n",
    "#print(data)\n",
    "\n",
    "data2 = data[data.id==105500404289]\n",
    "#data2 = data[data.foreclosure_date.notnull()]\n",
    "#print(data2.head(5))\n",
    "#print(data2[data2.columns[1]])\n",
    "#print(data2.loc[:,['id','reporting_period','servicer_name','balance','loan_age','maturity_date','delinquency_status',\n",
    "#                  'foreclosure_date','disposition_date','foreclosure_costs']])\n",
    "\n",
    "#print(len(data2))\n",
    "print(data2)\n",
    "\n",
    "#print(data.delinquency_status.unique())\n",
    "#newdf = data[data.columns[14:16]]\n",
    "#print(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
