{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athiq.ahmed\\AppData2\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open('X.pickle','rb'))\n",
    "y = pickle.load(open('y.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 200, 200, 1), dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [0]\n",
    "layer_sizes = [128]\n",
    "conv_layers = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-conv-128-nodes-0-dense-1537203498\n",
      "Train on 207 samples, validate on 90 samples\n",
      "Epoch 1/10\n",
      "207/207 [==============================] - 70s 337ms/step - loss: 0.8793 - acc: 0.5507 - val_loss: 0.6938 - val_acc: 0.4444\n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 75s 362ms/step - loss: 0.6809 - acc: 0.6425 - val_loss: 0.6045 - val_acc: 0.7111\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 76s 366ms/step - loss: 0.6012 - acc: 0.7005 - val_loss: 0.5627 - val_acc: 0.7111\n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 76s 369ms/step - loss: 0.5418 - acc: 0.7488 - val_loss: 0.5588 - val_acc: 0.7111\n",
      "Epoch 5/10\n",
      "207/207 [==============================] - 71s 345ms/step - loss: 0.4770 - acc: 0.7536 - val_loss: 0.5230 - val_acc: 0.7000\n",
      "Epoch 6/10\n",
      "207/207 [==============================] - 72s 349ms/step - loss: 0.4579 - acc: 0.7681 - val_loss: 0.5525 - val_acc: 0.6889\n",
      "Epoch 7/10\n",
      "207/207 [==============================] - 72s 349ms/step - loss: 0.3855 - acc: 0.8744 - val_loss: 0.5290 - val_acc: 0.7444\n",
      "Epoch 8/10\n",
      "207/207 [==============================] - 73s 351ms/step - loss: 0.2996 - acc: 0.9227 - val_loss: 0.6192 - val_acc: 0.7444\n",
      "Epoch 9/10\n",
      "207/207 [==============================] - 73s 350ms/step - loss: 0.2639 - acc: 0.8889 - val_loss: 0.6057 - val_acc: 0.7222\n",
      "Epoch 10/10\n",
      "207/207 [==============================] - 72s 350ms/step - loss: 0.2288 - acc: 0.9179 - val_loss: 0.8175 - val_acc: 0.7222\n"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            print(NAME)\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size,(3,3), input_shape = X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size,(3,3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                         optimizer='adam',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X,y,batch_size=32,epochs = 10, validation_split=0.3, callbacks=[tensorboard])\n",
    "            \n",
    "model.save('32x1-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow\n",
    "\n",
    "CATEGORIES = [\"Dettol\", \"Non-Dettol\"]    # will use this to convert prediction num to string value\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 200\n",
    "    img_array = cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)   # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))   # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)     # return the image with shaping that TF wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.models.load_model('32x1-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "Dettol\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('dettol_pic 5.jpg')])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9932495e-37]]\n",
      "Dettol\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('dettol_mix 9.jpg')])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "Non-Dettol\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('non dettol.jpg')])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "Dettol\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('non dettol 7.jpg')])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
