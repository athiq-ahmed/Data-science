{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Risk\n",
    "Predict whether people are a good or bad credit risk  \n",
    "Last modified: May 16th 2017\n",
    "### Skytree 16.0 Python SDK Demonstration\n",
    "Execution of the code in this demonstration produces the equivalent project in the Skytree graphical user interface  \n",
    "In the Jupyter (iPython) notebook, all cells can executed at once via \"Run All\", executed individually, or the code exported as a .py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Problem\n",
    " - A credit card company has customers who have varying degrees of credit risk\n",
    " - They would like to predict which for new applicants who are likely to be a bad credit risk\n",
    " - This will enable better decisions to be made about whom to extend credit to and how much\n",
    " - We will build a supervised machine learning model to predict credit risk for this company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up Skytree\n",
    "Here, we import the needed Skytree modules for this project  \n",
    "Any Python module may also be imported as part of the dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skytree\n",
    "import skytree.prediction\n",
    "from skytree import DatasetConfig\n",
    "from skytree.prediction import AutoModelConfig, GbtConfig, GbtrConfig\n",
    "\n",
    "hostname = 'http://localhost:8080/v1'\n",
    "username = 'trial@infosys.com'\n",
    "password = 'Infosys1' # Plain text passwords can be avoided using the Python getpass module\n",
    "datadir = '/user/infosys/datasets/'\n",
    "projectname = 'Credit Risk Prediction'\n",
    "projectdesc = 'Predict whether people are a good or bad credit risk'\n",
    "\n",
    "skytree.authenticate(username, password, hostname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our project to include our datasets, models, results, and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project = skytree.create_project(projectname, projectdesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "### 3.1: Load Data\n",
    "The create_dataset() project method loads data directly from HDFS  \n",
    "Alternatively, a local file path can be specified  \n",
    "Data can include numerical, categorical, sparse, and text columns  \n",
    "Options not shown include dataset delimiter, and dataset configuration, e.g., ID column  \n",
    "The .ready() blocking call ensures that this step in the dataflow is executed before further steps are attempted  \n",
    "Datasets can also be retrieved by ID within an existing project, and viewed by functions such as .summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = project.create_dataset(\n",
    "    url = 'hdfs://{0}/credit_risk_prediction.csv'.format(datadir), \n",
    "    has_header = True, \n",
    "    missing_value = '?',\n",
    "    name = 'Credit Data'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Add ID Column\n",
    "The data as supplied does not include a column containing unique row identifications, so we add one  \n",
    "For training, ID is optional, but it is required for model testing or deployment  \n",
    "This is because file line ordering is not necessarily preserved on a Hadoop distributed system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.add_unique_id_column(\n",
    "    'ID',\n",
    "    name = 'Credit Data With ID'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Commit Dataset\n",
    "By default, Skytree does not attempt to load the full data immediately, which may be large  \n",
    "To indicate that the whole data is to be used, we \"commit\" the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<id=1640286499329128763, name=\"Credit Data With ID\">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.commit().ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.4: Transform Snippets\n",
    "Skytree transform snippets allow arbitrary data preparation at scale using PySpark  \n",
    "Shared snippets either supplied with the software or user-defined can also be used directly in the GUI without coding  \n",
    "\n",
    "Here, we normalize the current_balance column since it is on a significantly different scale to the others  \n",
    "We could also normalize all columns or just run an algorithm where normalization is not needed, such as decision trees\n",
    "\n",
    "Snippets can be shown in \"preview\" form, which shows how the transform looks on the top 20 rows, allowing interactive development, and \"execute\" form, which applies the snippet to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Normalize_unit\n",
      "Description: Rescaling to between minimum (default: 0) and maximum (default:1 ).\n",
      "Id: 6590250852614889942\n",
      "Visibility: Public\n",
      "Input Arguments:\n",
      "\tcolToNormalize of type: COLUMN with allowed types: [u'LongType', u'DoubleType'] from: df\n",
      "Parameters:\n",
      "\tmin of type: float kind: OPTIONAL default value: None\n",
      "\tmax of type: float kind: OPTIONAL default value: None\n",
      "Output Arguments:\n",
      "\todf of type: DATAFRAME with allowed types: None from: None\n",
      "Code:\n",
      "\n",
      "# unitization with zero minimum ((x - min)/(max - min))\n",
      "if min is None:\n",
      "    min = df.agg({colToNormalize: 'min'}).collect()[0][0]\n",
      "\n",
      "if max is None:\n",
      "    max = df.agg({colToNormalize: 'max'}).collect()[0][0]\n",
      "\n",
      "range = max - min\n",
      "if range==0:\n",
      "    odf = df.withColumn(colToNormalize, 0)\n",
      "else:\n",
      "    odf = df.withColumn(colToNormalize, (df[colToNormalize] - min)/range )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print skytree.get_snippet_by_name('Normalize_unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS:\n",
      ">>> \n",
      ">>> import re\n",
      ">>> import os\n",
      ">>> from hdfs.ext.kerberos import KerberosClient\n",
      ">>> from hdfs import InsecureClient\n",
      ">>> from pyspark import SparkContext, SparkConf\n",
      ">>> from pyspark.sql import SQLContext\n",
      ">>> from pyspark.sql.types import *\n",
      ">>> import datasets\n",
      ">>> from datasets import DatasetReader, DatasetWriter, DatasetInfo\n",
      ">>> import sys\n",
      ">>> \n",
      ">>> sqlContext = SQLContext(sc)\n",
      ">>> \n",
      ">>> ds_info = datasets.DatasetInfo('/user/skytree/skytree/data_json/4609396799457303962/data/datasets/1640286499329128763/1640286499329128763.transformed.data', '/user/skytree/skytree/data_json/4609396799457303962/data/datasets/1640286499329128763/1640286499329128763.transformed.header', True, ',', 'ID', '?')\n",
      ">>> reader = datasets.DatasetReader(ds_info)\n",
      ">>> df = reader.spark_dataframe(sc, sqlContext)\n",
      ">>> colToNormalize = 'current_balance'\n",
      ">>> min = None\n",
      ">>> max = None\n",
      ">>> \n",
      ">>> \n",
      ">>> # unitization with zero minimum ((x - min)/(max - min))\n",
      ">>> if min is None:\n",
      "...     min = df.agg({colToNormalize: 'min'}).collect()[0][0]\n",
      "... \n",
      ">>> if max is None:\n",
      "...     max = df.agg({colToNormalize: 'max'}).collect()[0][0]\n",
      "... \n",
      ">>> range = max - min\n",
      ">>> if range==0:\n",
      "...     odf = df.withColumn(colToNormalize, 0)\n",
      "... else:\n",
      "...     odf = df.withColumn(colToNormalize, (df[colToNormalize] - min)/range )\n",
      "... \n",
      ">>> \n",
      ">>> odf.show(20)\n",
      "+-----------+------------+--------------------+-------------------+--------------------+----------------------+----------+--------+------------------+-------------+---------------+------------------+------+-------------------+--------+----------------+--------------------+--------------+-------------+--------------+-----+---+\n",
      "| over_draft|credit_usage|      credit_history|            purpose|     current_balance|Average_Credit_Balance|employment|location|   personal_status|other_parties|residence_since|property_magnitude|cc_age|other_payment_plans| housing|existing_credits|                 job|num_dependents|own_telephone|foreign_worker|class| ID|\n",
      "+-----------+------------+--------------------+-------------------+--------------------+----------------------+----------+--------+------------------+-------------+---------------+------------------+------+-------------------+--------+----------------+--------------------+--------------+-------------+--------------+-----+---+\n",
      "|         <0|           6|critical/other ex...|           radio/tv| 0.05056674369979091|      no known savings|       >=7|       4|       male single|         none|              4|       real estate|    67|               none|     own|               2|             skilled|             1|          yes|           yes| good|  0|\n",
      "|   0<=X<200|          48|       existing paid|           radio/tv|    0.31368988665126|                  <100|    1<=X<4|       2|female div/dep/mar|         none|              2|       real estate|    22|               none|     own|               1|             skilled|             1|         none|           yes|  bad|  2|\n",
      "|no checking|          12|critical/other ex...|          education| 0.10157367668097282|                  <100|    4<=X<7|       2|       male single|         none|              3|       real estate|    49|               none|     own|               1|  unskilled resident|             2|         none|           yes| good|  4|\n",
      "|         <0|          42|       existing paid|furniture/equipment|  0.4199405744470122|                  <100|    4<=X<7|       2|       male single|    guarantor|              4|    life insurance|    45|               none|for free|               1|             skilled|             2|         none|           yes| good|  6|\n",
      "|         <0|          24|  delayed previously|            new car| 0.25420931000330144|                  <100|    1<=X<4|       3|       male single|         none|              4| no known property|    53|               none|for free|               2|             skilled|             2|         none|           yes|  bad|  8|\n",
      "|no checking|          36|       existing paid|          education|  0.4844833278309673|      no known savings|    1<=X<4|       2|       male single|         none|              4| no known property|    35|               none|for free|               1|  unskilled resident|             2|          yes|           yes| good| 10|\n",
      "|no checking|          24|       existing paid|furniture/equipment| 0.14223616154946628|           500<=X<1000|       >=7|       3|       male single|         none|              4|    life insurance|    53|               none|     own|               1|             skilled|             1|         none|           yes| good| 12|\n",
      "|   0<=X<200|          36|       existing paid|           used car|  0.3685484758446132|                  <100|    1<=X<4|       2|       male single|         none|              2|               car|    35|               none|    rent|               1|high qualif/self ...|             1|          yes|           yes| good| 14|\n",
      "|no checking|          12|       existing paid|           radio/tv| 0.15456146142841423|                >=1000|    4<=X<7|       2|      male div/sep|         none|              4|       real estate|    61|               none|     own|               1|  unskilled resident|             1|         none|           yes| good| 16|\n",
      "|   0<=X<200|          30|critical/other ex...|            new car| 0.27423792230659183|                  <100|unemployed|       4|      male mar/wid|         none|              2|               car|    28|               none|     own|               2|high qualif/self ...|             1|         none|           yes|  bad| 18|\n",
      "|   0<=X<200|          12|       existing paid|            new car| 0.05749972488169913|                  <100|        <1|       3|female div/dep/mar|         none|              1|               car|    25|               none|    rent|               1|             skilled|             1|         none|           yes|  bad| 20|\n",
      "|         <0|          48|       existing paid|           business|  0.2232860129855838|                  <100|        <1|       3|female div/dep/mar|         none|              4|    life insurance|    24|               none|    rent|               1|             skilled|             1|         none|           yes|  bad| 22|\n",
      "|   0<=X<200|          12|       existing paid|           radio/tv| 0.07246616044899307|                  <100|    1<=X<4|       1|female div/dep/mar|         none|              1|               car|    22|               none|     own|               1|             skilled|             1|          yes|           yes| good| 24|\n",
      "|         <0|          24|critical/other ex...|            new car| 0.05221745350500715|                  <100|       >=7|       4|       male single|         none|              4|               car|    60|               none|     own|               2|  unskilled resident|             1|         none|           yes|  bad| 26|\n",
      "|         <0|          15|       existing paid|            new car| 0.06344228018047761|                  <100|    1<=X<4|       2|female div/dep/mar|         none|              4|               car|    28|               none|    rent|               1|             skilled|             1|         none|           yes| good| 28|\n",
      "|         <0|          24|       existing paid|           radio/tv|0.056784417299438755|            100<=X<500|    1<=X<4|       4|female div/dep/mar|         none|              2|               car|    32|               none|     own|               1|  unskilled resident|             1|         none|           yes|  bad| 30|\n",
      "|no checking|          24|critical/other ex...|           radio/tv| 0.11962143721800374|      no known savings|       >=7|       4|       male single|         none|              4|    life insurance|    53|               none|     own|               2|             skilled|             1|         none|           yes| good| 32|\n",
      "|         <0|          30| no credits/all paid|           business| 0.43039506988004844|      no known savings|        <1|       2|       male single|         none|              3|               car|    25|               bank|     own|               3|             skilled|             1|         none|           yes| good| 34|\n",
      "|   0<=X<200|          24|       existing paid|           used car|   0.678386706283702|                  <100|       >=7|       4|female div/dep/mar|         none|              2| no known property|    44|               none|for free|               1|high qualif/self ...|             1|          yes|           yes|  bad| 36|\n",
      "|no checking|          24|       existing paid|           radio/tv| 0.17497523935292175|           500<=X<1000|       >=7|       3|       male single|         none|              2|               car|    31|               none|     own|               1|             skilled|             2|          yes|           yes| good| 38|\n",
      "+-----------+------------+--------------------+-------------------+--------------------+----------------------+----------+--------+------------------+-------------+---------------+------------------+------+-------------------+--------+----------------+--------------------+--------------+-------------+--------------+-----+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'SUCCESS'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.configure_snippets_transform() \\\n",
    "    .addSnippet('Normalize_unit') \\\n",
    "        .setInputVar('colToNormalize', 'current_balance', dataset_id=data.id) \\\n",
    "        .setOutputVar('odf', assign_name='transformed', \\\n",
    "                      output_dataset_name='Credit Data Transformed', id_column='ID') \\\n",
    "    .preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = data.configure_snippets_transform() \\\n",
    "    .addSnippet('Normalize_unit') \\\n",
    "        .setInputVar('colToNormalize', 'current_balance', dataset_id=data.id) \\\n",
    "        .setOutputVar('odf', assign_name='transformed', \\\n",
    "                      output_dataset_name='Credit Data Transformed', id_column='ID') \\\n",
    "    .execute()\n",
    "    \n",
    "data_transformed = output[0]\n",
    "data_transformed = data_transformed.ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: Split Into Training and Testing Sets\n",
    "Splits can also be done into more than 2 files, e.g., training, tuning, and testing sets  \n",
    "Splitting a file is not required in Skytree: machine learning training can be done with holdout, cross-validation, or Monte Carlo cross-validation on a single file, with portions of the dataset held out as appropriate  \n",
    "Or, the user can specify a separate dataset to use for model tuning  \n",
    "A separate testing set file is required for Predict & Evaluate, shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<id=7941020574107658642, name=\"Credit Testing\">"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training, testing = data_transformed.split(\n",
    "    split_ratios = [7,3],\n",
    "    split_seed = 123456,\n",
    "    names = ['Credit Training','Credit Testing'], \n",
    "    configs = [DatasetConfig(id_column='ID'), \n",
    "               DatasetConfig(id_column='ID')])\n",
    "\n",
    "training.ready()\n",
    "testing.ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Machine Learning\n",
    "### 4.1: Gradient Boosted Tree Grid Search\n",
    "The first model is a gradient boosted tree (GBT) grid search with some values of tree depth and learning rate  \n",
    "We begin by setting up the model configuration  \n",
    "Not all of these options are required, and many more are available, e.g., point and score weights, ensemble GBT, class imbalance handling, other GBT hyperparameters and classification metrics, precision at k, rank-based loss functions, stochastic GBT, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import default GBT model configuration\n",
    "gbt_gs_config = GbtConfig()\n",
    "\n",
    "# K-fold cross-validation\n",
    "gbt_gs_config.num_folds = 5\n",
    "\n",
    "# Search 3 tree depths ...\n",
    "gbt_gs_config.tree_depth = [2,3,4]\n",
    "\n",
    "# ... in combination with 3 learning rates = grid of 9 points\n",
    "gbt_gs_config.learning_rate = [0.02,0.04,0.06]\n",
    "\n",
    "# Trees is automatically tuned over 10%:10%:100% = 10:10:100 trees here -> 90 grid points\n",
    "gbt_gs_config.num_trees = [100]\n",
    "\n",
    "# Make search reproducible\n",
    "gbt_gs_config.holdout_seed = 123456\n",
    "\n",
    "# Tune for Gini index\n",
    "gbt_gs_config.testing_objective = 'GINI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Train GBT on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbt_gs_model = skytree.prediction.learn(\n",
    "    training, \n",
    "    objective_column = 'class', \n",
    "    config = gbt_gs_config,\n",
    "    name = 'GBT Grid Search'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "Apply trained model to unseen testing data  \n",
    "This is equivalent to running \"Predict & Evaluate\" in the GUI  \n",
    "The results (ROC curve, etc.) can be seen under the \"Results\" tab, or accessed from the SDK via .summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_gs_results = gbt_gs_model.test(\n",
    "    testing,\n",
    "    name = 'Testing GBT Grid Search'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Gradient Boosted Tree Smart Search\n",
    "By default the smart search has various limits on its parameter ranges  \n",
    "These can be manually adjusted if desired  \n",
    "Here, we decrease the maximum number of trees because this is a small demonstration dataset  \n",
    "We then run setup, training, and testing, this time using a holdout instead of cross-validation  \n",
    "The seeds and regularization are set manually for reproducility of creating the demo  \n",
    "If not set, the seeds used are recorded as part of the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbt_ss_config = GbtConfig()\n",
    "\n",
    "gbt_ss_config.holdout_ratio = 0.3\n",
    "gbt_ss_config.smart_search = True\n",
    "gbt_ss_config.smart_search_iterations = 50\n",
    "gbt_ss_config.num_trees = {'max': 100}\n",
    "gbt_ss_config.testing_objective = 'GINI'\n",
    "\n",
    "gbt_ss_config.holdout_seed = 234567\n",
    "gbt_ss_config.smart_search_seed = 234567\n",
    "gbt_ss_config.table_sampling_seed = 234567\n",
    "gbt_ss_config.regularization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbt_ss_model = skytree.prediction.learn(\n",
    "    training,\n",
    "    'class',\n",
    "    gbt_ss_config,\n",
    "    name = 'GBT Smart Search'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbt_ss_results = gbt_ss_model.test(\n",
    "    testing,\n",
    "    name = 'Testing GBT Smart Search'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: AutoModel\n",
    "AutoModel is able to run multiple machine learning algorithms  \n",
    "It acts as a generalization of Smart Search by both navigating the algorithm hyperparameter spaces and choosing between algorithms at each iteration  \n",
    "Some of the algorithms require numerical-only data. Therefore, AutoModel ignores categorical columns (which can include missing values) for these algorithms so that they can be run  \n",
    "This means that AutoModel can be run directly on the same income data as the grid and smart searches above\n",
    "\n",
    "Note the AutoModel performance is competitive with the other methods (Smart Search and grid), but is simpler to run because it is not required to choose which algorithm to run, or to set algorithm hyperparameters  \n",
    "In fact, AutoModel can even be run with fewer than the auto_config parameters given here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_config = AutoModelConfig() \n",
    "\n",
    "auto_config.holdout_ratio = 0.3\n",
    "auto_config.holdout_seed = 234567\n",
    "auto_config.smart_search_iterations = 30\n",
    "auto_config.smart_search_seed = 234567\n",
    "auto_config.testing_objective = 'GINI'\n",
    "\n",
    "auto_model = skytree.prediction.learn(\n",
    "    training,\n",
    "    'class',\n",
    "    auto_config,\n",
    "    name = 'Automodel'\n",
    ").ready()\n",
    "\n",
    "auto_results = auto_model.test(\n",
    "    testing,\n",
    "    name = 'Testing AutoModel'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: AutoModel with AutoFeaturization\n",
    "Besides AutoModel running required prerequisite transforms, we can also run it with auto-featurization  \n",
    "Currently Skytree's built in auto-featurization is quite basic, but it will rapidly expand in future releases  \n",
    "Auto-featurization creates a new dataset with normalized numerical columns, horizontalized categorical columns, missing values imputed, and zero variance columns removed  \n",
    "This means that columns that would be ignored when only the prerequisite transforms are run can still be utilized in AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto_model_f = skytree.prediction.learn(\n",
    "    training,\n",
    "    'class',\n",
    "    auto_config,\n",
    "    name = 'Automodel with AutoFeaturize',\n",
    "    autoFeaturize = True\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, AutoModel can then be run on an unseen testing set  \n",
    "With auto-featurization switched on, the resulting interpretation is in terms of the columns created after featurization (e.g., the horizontalized ones)  \n",
    "This may be improved in future releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto_results_f = auto_model_f.test(\n",
    "    testing,\n",
    "    name = 'Testing AutoModel with AutoFeaturize'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5: Other Predictions\n",
    "#### Regression\n",
    "Other predictions can be performed on the data, e.g., regression to predict someone's credit usage instead of their risk  \n",
    "Here, we run GBT regression with Smart Search  \n",
    "As with classification, many further options are available such as other regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtr_ss_config = GbtrConfig()\n",
    "\n",
    "gbtr_ss_config.holdout_ratio = 0.3\n",
    "gbtr_ss_config.smart_search = True\n",
    "gbtr_ss_config.smart_search_iterations = 30\n",
    "gbtr_ss_config.testing_objective = 'MEAN_ABSOLUTE_ERROR'\n",
    "\n",
    "gbtr_ss_config.holdout_seed = 234567\n",
    "gbtr_ss_config.smart_search_seed = 234567\n",
    "gbtr_ss_config.table_sampling_seed = 234567\n",
    "gbtr_ss_config.regularization = False\n",
    "\n",
    "gbtr_ss_model = skytree.prediction.learn(\n",
    "    training,\n",
    "    'credit_usage',\n",
    "    gbtr_ss_config,\n",
    "    name = 'GBTR Smart Search'\n",
    ").ready()\n",
    "\n",
    "gbtr_ss_results = gbtr_ss_model.test(\n",
    "    testing,\n",
    "    name = 'Testing GBTR Smart Search'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass\n",
    "Multiclass classification allows prediction of a column with more than 2 classes, e.g., overdraft  \n",
    "Running this model on a testing set yields a multiclass confusion matrix viewable under the GUI \"Results\" tab  \n",
    "For multiclass, Gini index is not defined, so the testing objective is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_mc_config = GbtConfig()\n",
    "\n",
    "gbt_mc_config.holdout_ratio = 0.3\n",
    "gbt_mc_config.smart_search = True\n",
    "gbt_mc_config.smart_search_iterations = 30\n",
    "gbt_mc_config.testing_objective = 'ACCURACY'\n",
    "\n",
    "gbt_mc_config.holdout_seed = 234567\n",
    "gbt_mc_config.smart_search_seed = 234567\n",
    "gbt_mc_config.table_sampling_seed = 234567\n",
    "gbt_mc_config.regularization = False\n",
    "\n",
    "gbt_mc_model = skytree.prediction.learn(\n",
    "    training,\n",
    "    'over_draft',\n",
    "    gbt_mc_config,\n",
    "    name = 'GBT Smart Search Multiclass'\n",
    ").ready()\n",
    "\n",
    "gbt_mc_results = gbt_mc_model.test(\n",
    "    testing,\n",
    "    name = 'Testing GBT Smart Search Multiclass'\n",
    ").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6: Other Models\n",
    "Other machine learning algorithms that can be run in the GUI and SDK include generalized linear models, random decision forest, and support vector machine  \n",
    "In the command line, we also support clustering, nearest neighbors, density estimation, dimension reduction, and recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plots\n",
    "We show partial dependence, capture deviation, and predicted versus true value plots  \n",
    "Each plot is also easily generated in the GUI\n",
    "### 5.1: AutoModel 1D Partial Dependence Plots\n",
    "Partial dependencies (PDPs) give a lot of detailed insight beyond simple variable importances or performance metrics\n",
    "\n",
    "E.g., the variable importances, viewable in the GUI, show the most significant predictors of credit risk in the AutoModel are whether or not the person has an overdraft, followed by credit purpose and current balance.\n",
    "\n",
    "The PDPs here show additional information, such as risk decreasing with higher credit usage and current balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_1d_1 = auto_model.visualize_pdp(\"PDP 1D: Credit Usage\",\"credit_usage\").ready()\n",
    "pdp_1d_2 = auto_model.visualize_pdp(\"PDP 1D: Current Balance\",\"current_balance\").ready()\n",
    "pdp_1d_3 = auto_model.visualize_pdp(\"PDP 1D: Overdraft\",\"over_draft\").ready()\n",
    "pdp_1d_4 = auto_model.visualize_pdp(\"PDP 1D: Purpose\",\"purpose\").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: AutoModel 2D Partial Dependence Plots\n",
    "Two dimensional PDPs show further insight, e.g., low credit usage being more important than age for risk, and, while overdraft is significant, the subset of people for whom, in this data, \"overdraft\" means not having a checking account at all, is even more significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdp_2d_1 = auto_model.visualize_pdp(\"PDP 2D: Age, Credit History\",\"cc_age\",\"credit_history\").ready()\n",
    "pdp_2d_2 = auto_model.visualize_pdp(\"PDP 2D: Age, Overdraft\",\"cc_age\",\"over_draft\").ready()\n",
    "pdp_2d_3 = auto_model.visualize_pdp(\"PDP 2D: Age, Purpose\",\"cc_age\",\"purpose\").ready()\n",
    "pdp_2d_4 = auto_model.visualize_pdp(\"PDP 2D: Credit Usage, Age\",\"credit_usage\",\"cc_age\").ready()\n",
    "pdp_2d_5 = auto_model.visualize_pdp(\"PDP 2D: Credit Usage, Credit History\",\"credit_usage\",\"credit_history\").ready()\n",
    "pdp_2d_6 = auto_model.visualize_pdp(\"PDP 2D: Credit Usage, Overdraft\",\"credit_usage\",\"over_draft\").ready()\n",
    "pdp_2d_7 = auto_model.visualize_pdp(\"PDP 2D: Credit Usage, Purpose\",\"credit_usage\",\"purpose\").ready()\n",
    "pdp_2d_8 = auto_model.visualize_pdp(\"PDP 2D: Overdraft, Credit History\",\"over_draft\",\"credit_history\").ready()\n",
    "pdp_2d_9 = auto_model.visualize_pdp(\"PDP 2D: Overdraft, Purpose\",\"over_draft\",\"purpose\").ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Capture Deviation Plot\n",
    "Capture deviation shows how well the class probabilities were modeled  \n",
    "Ideally the predicted class probability always matches the true class probability as seen from the testing set, yielding points on the diagonal line, which corresponds to a capture deviation of zero  \n",
    "Here we show the capture deviation for credit risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture Deviation Plot (Classification)\n",
      "1084506945850907\n",
      "Prediction Vs Actual (Regression)\n",
      "5094586945860902\n",
      "{\n",
      "    \"columns\": [\"Objective Column\", \"Predicted Probabilities\", \"Predicted Labels\", \"Predicted Categories\"],\n",
      "    \"summarizer\": [\n",
      "        {\n",
      "            \"name\": \"numBuckets\",\n",
      "            \"kind\": \"optional\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"default\": 10\n",
      "        }\n",
      "    ],\n",
      "    \"plot\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from skytree.prediction import Plot, PlotRegistry\n",
    "registry = PlotRegistry(project)\n",
    "resource_id = registry.findall(\"TESTRESULT\")\n",
    "for registry in resource_id:\n",
    "    print registry[\"name\"]\n",
    "    print registry[\"id\"]\n",
    "registry = PlotRegistry(project)\n",
    "plot_args = registry.findById(\"1084506945850907\")\n",
    "print plot_args[\"argsSpec\"]\n",
    "plot_args = \"{ \\\"columns\\\": [\\\"Objective Column\\\", \\\"Predicted Probabilities\\\",\\\n",
    "\\\"Predicted Labels\\\", \\\"Predicted Categories\\\"],\\\n",
    "\\\"summarizer\\\": [ { \\\"name\\\": \\\"numBuckets\\\", \\\"kind\\\": \\\"fixed\\\",\\\n",
    "\\\"type\\\": \\\"integer\\\", \\\"default\\\": 10 } ], \\\"plot\\\": [] }\"\n",
    "plot_name = \"Capture Deviation for Credit Risk\"\n",
    "plot_registry_id = \"1084506945850907\"\n",
    "plot = auto_results.visualize(plot_args, plot_name, plot_registry_id).ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4: Predicted Versus True Values\n",
    "For regression problems, we can see predicted versus true values for a testing set  \n",
    "This shows predicted versus true for credit usage  \n",
    "The model shows some correlation, but with significant spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture Deviation Plot (Classification)\n",
      "1084506945850907\n",
      "Prediction Vs Actual (Regression)\n",
      "5094586945860902\n",
      "{\n",
      "    \"columns\": [\"Objective Column\", \"Predicted Targets\"],\n",
      "    \"summarizer\": [\n",
      "        {\n",
      "            \"name\": \"returnSize\",\n",
      "            \"kind\": \"fixed\",\n",
      "            \"type\" : \"integer\",\n",
      "            \"default\": 10000\n",
      "        }\n",
      "    ],\n",
      "    \"plot\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "registry = PlotRegistry(project)\n",
    "resource_id = registry.findall(\"TESTRESULT\")\n",
    "for registry in resource_id:\n",
    "    print registry[\"name\"]\n",
    "    print registry[\"id\"]\n",
    "resource = PlotRegistry(project)\n",
    "plot_args = resource.findById(\"5094586945860902\")\n",
    "print plot_args[\"argsSpec\"]\n",
    "plot_args = \"{ \\\"columns\\\": [\\\"Objective Column\\\", \\\"Predicted Targets\\\"],\\\n",
    "\\\"summarizer\\\": [ { \\\"name\\\": \\\"returnSize\\\", \\\"kind\\\": \\\"fixed\\\",\\\n",
    "\\\"type\\\": \\\"integer\\\", \\\"default\\\": 10000 } ], \\\"plot\\\": [] }\"\n",
    "plot_name = \"Predicted vs. Actual for Credit Usage\"\n",
    "plot_registry_id = \"5094586945860902\"\n",
    "plot = gbtr_ss_results.visualize(plot_args, plot_name, plot_registry_id).ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n",
    " - We built a supervised machine learning model using Skytree to predict whether people are a good or bad credit risk\n",
    " - The model classified about 74% of the transactions correctly\n",
    " - The most significant predictors of credit risk are presence of an overdraft, followed by credit purpose and current balance\n",
    " - The probability of being a bad credit risk, and the reasons given, determine the most appropriate course of action for each transaction\n",
    " - The customers win, from receiving better screening\n",
    " - The business wins, via less money being lost to extending undue credit to customers who are a bad risk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
